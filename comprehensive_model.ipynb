{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import dask.array as da\n",
    "import torch \n",
    "import os \n",
    "from glob import glob\n",
    "from utils import get_train_test_data_without_scales_batched, get_train_test_data_without_scales_batched_monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Acer\\.conda\\envs\\weather\\lib\\site-packages\\xarray\\groupers.py:326: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  self.index_grouper = pd.Grouper(\n",
      "c:\\Users\\Acer\\.conda\\envs\\weather\\lib\\site-packages\\xarray\\core\\indexes.py:561: FutureWarning: 'H' is deprecated and will be removed in a future version. Please use 'h' instead of 'H'.\n",
      "  flat_indexer = index.get_indexer(flat_labels, method=method, tolerance=tolerance)\n"
     ]
    }
   ],
   "source": [
    "data = xr.open_mfdataset('data/geopotential_500_5.625deg/*.nc', combine='by_coords')\n",
    "data = data.resample(time=\"6H\").nearest(\n",
    "    tolerance=\"1H\")  # Setting data to be 6-hour cycles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_train_test_data_without_scales_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_time_scale = slice('2006', '2016')\n",
    "val_time_scale = slice('2016', '2016')\n",
    "test_time_scale = slice('2017', '2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data.sel(time=train_time_scale).load()\n",
    "\n",
    "# 2016\n",
    "data_val = data.sel(time=val_time_scale).load()\n",
    "\n",
    "# 2017 - 2018\n",
    "data_test = data.sel(time=test_time_scale).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_global = data.sel(time=slice('2006', '2018')).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = data_global.max()[\"z\"].values.tolist()\n",
    "\n",
    "min_val = data_global.min()[\"z\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_final = (data_train - min_val) / (max_val - min_val)\n",
    "data_val_final = (data_val - min_val) / (max_val - min_val)\n",
    "data_test_final = (data_test - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_vals = data_test_final.time.values\n",
    "train_times = [i for i in range(2006, 2016)]\n",
    "test_times = [2017, 2018]\n",
    "val_times = [2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015]\n"
     ]
    }
   ],
   "source": [
    "print(train_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batched(train_times, data_train_final, lev):\n",
    "    for idx, year in enumerate(train_times):\n",
    "        data_per_year = data_train_final.sel(\n",
    "            time=slice(str(year), str(year))).load()\n",
    "        data_values = data_per_year[lev].values\n",
    "        print(f\"data_values shape: {data_values.shape} || at year: {year}\")\n",
    "\n",
    "        if idx == 0:\n",
    "            # has shape (time_values, 1, 1, 32, 64)  -> (time_values, year, channel, H, W) \n",
    "            train_data = torch.from_numpy(\n",
    "                data_values).reshape(-1, 1, 1, data_values.shape[-2], data_values.shape[-1])\n",
    "            print(f\"train_data shape: {train_data.shape}\")\n",
    "\n",
    "            if year % 4 == 0:\n",
    "                # skipping 29 feb in leap year\n",
    "                train_data = torch.cat((train_data[:236], train_data[240:]))\n",
    "        else:\n",
    "            mid_data = torch.from_numpy(\n",
    "                data_values).reshape(-1, 1, 1, data_values.shape[-2], data_values.shape[-1])\n",
    "            print(f\"train_data shape: {mid_data.shape}\")\n",
    "            if year % 4 == 0:\n",
    "                # skipping 29 feb in leap year\n",
    "                print(f\"Leap year: {year}\")\n",
    "                mid_data = torch.cat((mid_data[:236], mid_data[240:]))\n",
    "            train_data = torch.cat([train_data, mid_data], dim=1)\n",
    "\n",
    "    return train_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_values shape: (1460, 32, 64) || at year: 2006\n",
      "train_data shape: torch.Size([1460, 1, 1, 32, 64])\n",
      "data_values shape: (1460, 32, 64) || at year: 2007\n",
      "train_data shape: torch.Size([1460, 1, 1, 32, 64])\n",
      "data_values shape: (1464, 32, 64) || at year: 2008\n",
      "train_data shape: torch.Size([1464, 1, 1, 32, 64])\n",
      "Leap year: 2008\n",
      "data_values shape: (1460, 32, 64) || at year: 2009\n",
      "train_data shape: torch.Size([1460, 1, 1, 32, 64])\n",
      "data_values shape: (1460, 32, 64) || at year: 2010\n",
      "train_data shape: torch.Size([1460, 1, 1, 32, 64])\n",
      "data_values shape: (1460, 32, 64) || at year: 2011\n",
      "train_data shape: torch.Size([1460, 1, 1, 32, 64])\n",
      "data_values shape: (1464, 32, 64) || at year: 2012\n",
      "train_data shape: torch.Size([1464, 1, 1, 32, 64])\n",
      "Leap year: 2012\n",
      "data_values shape: (1460, 32, 64) || at year: 2013\n",
      "train_data shape: torch.Size([1460, 1, 1, 32, 64])\n",
      "data_values shape: (1460, 32, 64) || at year: 2014\n",
      "train_data shape: torch.Size([1460, 1, 1, 32, 64])\n",
      "data_values shape: (1460, 32, 64) || at year: 2015\n",
      "train_data shape: torch.Size([1460, 1, 1, 32, 64])\n"
     ]
    }
   ],
   "source": [
    "train_data_batched = get_batched(train_times=train_times, data_train_final=data_train_final, lev=\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_batched shape: torch.Size([1460, 10, 1, 32, 64])\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_data_batched shape: {train_data_batched.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weather",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
